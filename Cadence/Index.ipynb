{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cadence Optimization for AGN selection in LSST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling of observations is crucial to AGN selection by varaiablity. Here, we will be investigating how different proposed cadence for LSST can affect AGN selections, in particular we would like to see whether non-uniform cadence like rolling cadence will hurt AGN science in LSST. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic procdeuce is described below, with links to notebooks that expand each step in more details:\n",
    "1. Get LSST cadence and minimum seperation between two visits within one night using MAF\n",
    "2. Simulate mock light curves using [Kali](https://github.com/AstroVPK/kali), using CARMA(1,0)/Damped Random Walk(**DRW**) & CARMA(2,1)/Damped Harmonic Oscillator(**DHO**) model sampled at the minimum seperation obtained above. \n",
    "3. Downsample the mock LC at the LSST cadence obtained from step one.\n",
    "4, Use Kali to find the best-fit CARMA parameters and compare the best-fit parameters with input parameters used to generate the mock LCs to determine the quality of each cadence being tested.\n",
    "\n",
    "\n",
    "- step 1, see [Step 1](#Step-1)  \n",
    "- setp 2 - 3, see [Kali notebook](lc.ipynb)  \n",
    "- comparision between cadences, see [compare](compare.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Operation Simulator(OpSim) is a sofeware developed by the LSST DM team to simulate observing schedules in order to better optimize the LSST output for different science goals. Simulated observing schedules are stored in SQLite database files. The offical baseline cadence includes an universal Wide-Fast-Deep(WFD) main survey and several mini-surveys such as the Deep Drilling Fields(DDFs). The WFD survey will scan the sky uniformly and covers entire visible sky within approximately 3 days. A detailed description for the current baseline survey and different variations can be obtained from the [LSST Observing Strategy White Paper](https://arxiv.org/pdf/1708.04058.pdf). The links to the database files storing the observing schedules, with short description of each cadence, is available fron the offical [LSST web page](https://www.lsst.org/scientists/simulations/opsim/lsst-survey-strategy).  \n",
    "\n",
    "The Metrics Analysis Framework(MAF) is another tools developed by the LSST DM team for easy access and analysis of OpSim output. In the rest of this notebook, I will show how to use MAF to get observing times and minimum seperation between visits within the same night given the RA and DEC for a paritcular location in the sky. The cadence used to demonstrate the workflow is minon_1016, the baseline cadence simulated using OpSim v3.3.5. The code can be used on all other simulated cadences(transion from OpSim v3 to v4 should be taken care of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0.sims'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lsst.sims.maf\n",
    "lsst.sims.maf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline   \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our python modules\n",
    "import lsst.sims.maf.db as db\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.stackers as stackers\n",
    "import lsst.sims.maf.plots as plots\n",
    "import lsst.sims.maf.metricBundles as metricBundles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minion_1016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import amin as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup database connection, path should be modified accordingly\n",
    "outDir ='minior_1016' # this is not important\n",
    "Baseline = '/home/mount/Opsim DB/minion_1016_sqlite.db'\n",
    "\n",
    "# specify output directory for metrics result\n",
    "resultsDb = db.ResultsDb(outDir=outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrive min inter_night gap, and observation history with the input of database file name and\n",
    "# arrays of RA and DEC\n",
    "def find_min_gap(dbFile, ra, dec):\n",
    "    # establish connection to sqllite database file\n",
    "    opsimdb = db.OpsimDatabase(dbFile)\n",
    "    \n",
    "    # While we're in transition between opsim v3 and v4, this may be helpful:\n",
    "    # print(\"{dbFile} is an opsim version {version} database\".format(dbFile=dbFile, version=opsimdb.opsimVersion))\n",
    "    if opsimdb.opsimVersion == \"V3\":\n",
    "        # For v3 databases:\n",
    "        mjdcol = 'expMJD'\n",
    "        degrees = False\n",
    "    else:\n",
    "        # For v4 and alternate scheduler databases.\n",
    "        mjdcol = 'observationStartMJD'\n",
    "        degrees = True\n",
    "    \n",
    "    # IntraNightGapsMetric returns the gap (in days) between observations within the same night\n",
    "    # custom reduceFunc to find min gaps \n",
    "    metric = metrics.cadenceMetrics.IntraNightGapsMetric(reduceFunc=np.amin, mjdCol=mjdcol)\n",
    "    # PassMetric just pass all values\n",
    "    metric_pass = metrics.simpleMetrics.PassMetric(cols=['filter','fiveSigmaDepth', mjdcol, 'expDate'])\n",
    "    # slicer for slicing pointing history\n",
    "    slicer = slicers.UserPointsSlicer(ra, dec, lonCol='fieldRA', latCol='fieldDec', latLonDeg=degrees)\n",
    "    # sql constrains, here I put none\n",
    "    sql = '' #'night < 365'\n",
    "    \n",
    "    # bundles to combine metric, slicer and sql constrain together\n",
    "    bundle = metricBundles.MetricBundle(metric,slicer,sql)\n",
    "    date_bundle = metricBundles.MetricBundle(metric_pass, slicer, sql)\n",
    "    # In case you are using a dither stacker, we can check what columns are actually being pulled from the database.\n",
    "    print(bundle.dbCols)\n",
    "    \n",
    "    # create metric bundle group and returns\n",
    "    bg = metricBundles.MetricBundleGroup({'sep': bundle, 'cadence':date_bundle}, opsimdb, outDir=outDir, resultsDb=resultsDb)\n",
    "    bg.runAll()\n",
    "    opsimdb.close()\n",
    "    return bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify ra & dec\n",
    "ra = 58\n",
    "dec = -27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fieldDec', 'night', 'expMJD', 'fieldRA'}\n",
      "Querying database Summary with no constraint for columns ['expMJD', 'fieldDec', 'fieldRA', 'fiveSigmaDepth', 'filter', 'expDate', 'night'].\n",
      "Found 2447931 visits\n",
      "Running:  ['sep', 'cadence']\n",
      "Completed metric generation.\n",
      "Running reduce methods.\n",
      "Running summary statistics.\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "# Now baseline \n",
    "BL_result = find_min_gap(Baseline, ra, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign min intra_night gap in hours to gap\n",
    "gap = BL_result.bundleDict['sep'].metricValues.data[0]\n",
    "# assign pointing history to obsHist\n",
    "cadence = BL_result.bundleDict['cadence'].metricValues.data[0]\n",
    "# put ra, dec, and gap into array 'pos_gap'\n",
    "meta = [ra, dec, gap, 'minion_1016']\n",
    "\n",
    "# Now let's save it to a file, .npz will be automatically added\n",
    "outfile = '/home/mount/MAF output/58_-27_bl'\n",
    "np.savez(outfile, meta=meta, cadence=cadence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, I saved the MAF output to a npz file for later use. To load the data from the npz to a numpy array, just use `data = numpy.load(filename)` in the destination notebook. To checkout the arrays stored in the file, use `data.files`. To access the arrays stored, you can use `ar1 = data['filename1']`. For more verbose description, please checkout the [numpy documentation](https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my code, I saved two arrays into the file '58_-27_bl.npz' and give each array a name. The 'meta' array contains the ra, dec, minimum seperation between two visits within one night and the cadence ID. The cadence array stores the simulated observing data at that paricular location. First few record for the cadence array is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( 23.196984, -0.441474,  59583.081518,  3, 266243,  1.011712, 'u'),\n",
       "       ( 23.353786, -0.493128,  59584.110662,  4, 355161,  1.033665, 'u'),\n",
       "       ( 21.585248, -0.441474,  59588.098629,  8, 699721,  1.011712, 'y'),\n",
       "       ( 21.591766, -0.493128,  59588.099127,  8, 699764,  1.033665, 'y'),\n",
       "       ( 23.26137 , -0.441474,  59589.201819,  9, 795037,  1.011712, 'i'),\n",
       "       ( 21.871891, -0.441474,  59590.045663, 10, 867945,  1.011712, 'y'),\n",
       "       ( 22.65524 , -0.441474,  59591.094303, 11, 958547,  1.011712, 'z'),\n",
       "       ( 22.694526, -0.493128,  59591.094795, 11, 958590,  1.033665, 'z'),\n",
       "       ( 22.685024, -0.441474,  59591.11559 , 11, 960386,  1.011712, 'z'),\n",
       "       ( 22.728186, -0.493128,  59591.116061, 11, 960427,  1.033665, 'z')],\n",
       "      dtype=(numpy.record, [('fiveSigmaDepth', '<f8'), ('fieldDec', '<f8'), ('expMJD', '<f8'), ('night', '<i8'), ('expDate', '<i8'), ('fieldRA', '<f8'), ('filter', '<U256')]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadence[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
